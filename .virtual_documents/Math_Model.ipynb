














!pip install numpy pandas matplotlib seaborn scikit-learn plotly





import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn.preprocessing as sk
import plotly.express as px

from sklearn.metrics import confusion_matrix, mean_squared_error, mean_absolute_error, r2_score, roc_curve, auc

print('All imports were successful!')





dataset_math = pd.read_csv("resources/student-mat.csv",sep=";")
dataset_por = pd.read_csv("resources/student-por.csv",sep=";")

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

print('Dataset was loaded successfully!')





dataset_math.head()


dataset_math.tail()


dataset_math.info()


dataset_math.describe(include='all')


(dataset_math == 'yes').sum()


dataset_math.shape


# Defining target column
target = 'G3'

# To verify if it was created
print(target)


# Defining only the numerical columns
df = dataset_math.select_dtypes(include='int64')
df.head()


# Plotting histograms
df.hist(figsize=(15, 10), bins=10, color='red', edgecolor='blue')
plt.suptitle('Feature Distributions', fontsize=20)
plt.tight_layout()
plt.show()


# Making Boxplots
plt.figure(figsize =(20, 20))
for idx, col in enumerate(df):
    plt.subplot(4, 4, idx+1)
    sns.boxplot(x = f'{target}', y = col, data = df, palette = 'viridis')
    plt.title(f'{col} vs {target}')
    plt.xlabel(target)
    plt.ylabel(col)
    plt.grid(axis='y', linestyle='--', alpha = 0.7)
plt.tight_layout()
plt.show()


# Making the correlation heatmap

plt.figure(figsize=(25, 25))
sns.heatmap(df.corr(), annot=True, fmt='.2f', cmap='coolwarm', square=True)
plt.title('Correlation Matrix', fontsize=50)
plt.show()


# Identifying columns whose correlations do not meet the threshold

X = df.drop(target, axis=1)
y = df[target]

df_for_corr_analysis = pd.concat([X, y], axis=1)

feature_target_correlations = df_for_corr_analysis.corr().abs()[target].drop(target)
print(f'\nAbsolute Correlation of each feature with {target}:\n', feature_target_correlations)

correlation_threshold = 0.07

invalid_cols = feature_target_correlations[
    feature_target_correlations < correlation_threshold
].index.to_list()
print(f'\n\nLow Correlating Columns below {correlation_threshold}:\n{invalid_cols}')

number_of_remaining_cols = df.columns.size - len(invalid_cols) - 1
print(f'\n\nNumber of features remaining: {number_of_remaining_cols}')


# Removing the low correlating columns
df = df.drop(invalid_cols, axis=1)
df.head()





# Standardization
from sklearn.preprocessing import MinMaxScaler

X = df.drop(target, axis=1)
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

print('Dataset was scaled successfully')





from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, random_state=42)

print(f'Training Dataset Size: {X_train.shape}')
print(f'Testing Dataset Size: {X_test.shape}')
print(f'Target Training Size: {y_train.shape}')
print(f'Target Testing Size: {y_test.shape}')








from sklearn.linear_model import LinearRegression

model = LinearRegression()
model.fit(X_train, y_train)

print('______________ LINEAR REGRESSION MODEL ______________')

y_pred = model.predict(X_test)

# Model Evaluation
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse) # Root Mean Squared Error
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred) # R-squared (Coefficient of Determination)

print("\n--- Regression Model Evaluation ---")
print(f'Mean Squared Error (MSE): {mse:.4f}')
print(f'Root Mean Squared Error (RMSE): {rmse:.4f}')
print(f'Mean Absolute Error (MAE): {mae:.4f}')
print(f'R-squared (R2): {r2:.4f}')








import joblib

model_file_name = "math_model.pkl"
joblib.dump((scaler, model), model_file_name)
print(f'Model file {model_file_name} was successfully generated!')
